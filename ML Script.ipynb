{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> pd.Series:\n",
    "    csv_train = pd.read_csv('accidents.csv').assign(train = 1) \n",
    "    csv_test = pd.read_csv('test.csv').assign(train = 0) \n",
    "    csv_vehicles = pd.read_csv('vehicles.csv')\n",
    "    csv = pd.concat([csv_train,csv_test], sort=True)\n",
    "    return csv, csv_vehicles\n",
    "\n",
    "def nans_ctr(csv) -> pd.Series:\n",
    "    return csv.isna().sum()\n",
    "\n",
    "def unique_ctr(csv) -> pd.Series():\n",
    "    unique = pd.Series()\n",
    "    for col in list(csv):\n",
    "        if(csv.columns.contains(col)):\n",
    "            unique.at[col] = len(csv[col].unique())\n",
    "    return unique\n",
    "\n",
    "def val_types(csv) -> pd.Series():\n",
    "    val_type = pd.Series()\n",
    "    for col in list(csv):\n",
    "        if not csv.columns.contains(col):\n",
    "            continue\n",
    "        if csv[col].dtype == np.float64:\n",
    "            val_type.at[col] = np.float64\n",
    "        elif csv[col].dtype == np.int64:\n",
    "            val_type.at[col] = np.int64\n",
    "        elif csv[col].dtype == np.int32:\n",
    "            val_type.at[col] = np.int32\n",
    "        elif csv[col].dtype == np.uint8:\n",
    "            val_type.at[col] = np.uint8\n",
    "        elif csv[col].dtype == object:\n",
    "            val_type.at[col] = object\n",
    "        elif csv[col].dtype == bool:\n",
    "            val_type.at[col] = bool\n",
    "        else:\n",
    "            print(f\"No common value type found in val_types() - {csv[col].dtype}\")\n",
    "    return val_type\n",
    "\n",
    "def min_max_val(csv) -> pd.Series():\n",
    "    min_val = pd.Series()\n",
    "    max_val = pd.Series()\n",
    "    val_type = val_types(csv)\n",
    "    for col in list(csv):\n",
    "        if val_type[col] != object:\n",
    "            min_val.at[col] = csv[col].min()\n",
    "            max_val.at[col] = csv[col].max()\n",
    "        else:    \n",
    "            min_val.at[col] = None\n",
    "            max_val.at[col] = None\n",
    "    return min_val, max_val        \n",
    "            \n",
    "def get_stats(csv):\n",
    "    nans = nans_ctr(csv)\n",
    "    unique = unique_ctr(csv)\n",
    "    val_type = val_types(csv)\n",
    "    min_val, max_val = min_max_val(csv)\n",
    "    result = pd.DataFrame({ 'nans': nans, 'unique': unique, 'val_type': val_type, 'min_val': min_val, 'max_val': max_val}) \n",
    "    return result\n",
    "    \n",
    "def bool_to_integer(csv) -> pd.DataFrame():\n",
    "    for col in csv.columns:\n",
    "        if csv[col].dtype == bool:\n",
    "            csv[col] = csv[col].astype(int)\n",
    "    return csv\n",
    "    \n",
    "def standarize_numerical_values(csv):\n",
    "    for col in csv.columns:\n",
    "        if col == 'train':\n",
    "            continue\n",
    "        if csv[col].dtype == np.float64:\n",
    "            data = csv[col]\n",
    "            std = data.std()\n",
    "            data = data[(data < data.quantile(0.99)) & (data > data.quantile(0.01))]\n",
    "            mean = data.mean()\n",
    "            csv[col] = (csv[col] - mean)/std\n",
    "#             _ = plt.hist(csv[col], bins='auto', alpha = 0.5)\n",
    "#             plt.yscale('log')\n",
    "#             plt.title(f\"Distr in {col} column\")\n",
    "#             plt.show()\n",
    "    return csv\n",
    "\n",
    "def check_rows(csv):\n",
    "    for row in range(len(csv)):\n",
    "        print(row, csv.iloc[row].isna().sum())\n",
    "    return csv\n",
    "\n",
    "def distribution_in_columns(csv):\n",
    "    for col in list(csv):\n",
    "        print(csv[col].value_counts())\n",
    "    return csv\n",
    "        \n",
    "def plot_dist_y(csv):\n",
    "    plt.pie([len(csv[csv['Alignment'] == 'good']), len(csv[csv['Alignment'] == 'bad']), \n",
    "             len(csv[csv['Alignment'] == 'neutral'])], labels = ['good', 'bad', 'neutral'])\n",
    "    plt.show()\n",
    "    return csv\n",
    "    \n",
    "def factorize(csv, col_name, verbose=False) -> pd.DataFrame():\n",
    "    if csv[col_name].dtype == object:\n",
    "        dummy = pd.get_dummies(csv[col_name])\n",
    "        dummy.columns = [col_name+ \" \"+x for x in dummy.columns]\n",
    "#         dummy = dummy.drop([dummy.columns[-1]], axis=1)\n",
    "        csv = csv.drop(col_name, axis=1)\n",
    "        if verbose:\n",
    "            display(dummy.head())\n",
    "        csv = pd.concat([csv, dummy], axis=1)\n",
    "    else:\n",
    "        assert(\"factorize non object column\")\n",
    "    return csv\n",
    "\n",
    "def check_corelation(csv, col_1, col_2):\n",
    "    df_corr = pd.DataFrame()\n",
    "    df_corr[col_1] = csv[col_1].astype('category').cat.codes\n",
    "    df_corr[col_2]=csv[col_2]\n",
    "    df_corr = df_corr.dropna()\n",
    "    print(df_corr.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv, csv_vehicles = load_data()\n",
    "# get_stats(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = factorize(csv, \"1st_road_class\")\n",
    "csv = factorize(csv, \"2nd_road_class\")\n",
    "csv = factorize(csv, \"carriageway_hazards\")\n",
    "csv = factorize(csv, \"junction_control\")\n",
    "csv = factorize(csv, \"junction_detail\")\n",
    "\n",
    "csv = factorize(csv, \"pedestrian_crossing-human_control\")\n",
    "csv = factorize(csv, \"pedestrian_crossing-physical_facilities\")\n",
    "csv = factorize(csv, \"road_surface_conditions\")\n",
    "csv = factorize(csv, \"road_type\")\n",
    "csv = factorize(csv, \"special_conditions_at_site\")\n",
    "\n",
    "csv = factorize(csv, \"urban_or_rural_area\")\n",
    "csv = factorize(csv, \"special_conditions_at_site\")\n",
    "csv = factorize(csv, \"special_conditions_at_site\")\n",
    "csv = factorize(csv, \"special_conditions_at_site\")\n",
    "csv = factorize(csv, \"special_conditions_at_site\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.75 1.   0.   0.5 ]\n"
     ]
    }
   ],
   "source": [
    "csv[\"light_conditions\"] = csv[\"light_conditions\"].replace('Daylight', 1)\n",
    "csv[\"light_conditions\"] = csv[\"light_conditions\"].replace('Darkness - lights lit', 0.75)\n",
    "csv[\"light_conditions\"] = csv[\"light_conditions\"].replace('Darkness - lighting unknown', 0.5)\n",
    "csv[\"light_conditions\"] = csv[\"light_conditions\"].replace('-1', 0.5)\n",
    "csv[\"light_conditions\"] = csv[\"light_conditions\"].replace('Darkness - lights unlit', 0.25)\n",
    "csv[\"light_conditions\"] = csv[\"light_conditions\"].replace('Darkness - no lighting', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_corelation(csv, \"police_force\", 'target')    \n",
    "csv = csv.drop(\"police_force\", axis=1)\n",
    "csv = csv.drop(\"lsoa_of_accident_location\", axis=1)\n",
    "csv = csv.drop(\"local_authority_highway\", axis=1)\n",
    "csv = csv.drop(\"local_authority_district\", axis=1)\n",
    "\n",
    "csv = csv.drop(\"1st_road_number\", axis=1)\n",
    "csv = csv.drop(\"2nd_road_number\", axis=1)\n",
    "\n",
    "\n",
    "csv = csv.drop(\"location_easting_osgr\", axis=1)\n",
    "csv = csv.drop(\"location_northing_osgr\", axis=1)\n",
    "csv = csv.drop(\"2nd_road_number\", axis=1)\n",
    "csv = csv.drop(\"2nd_road_number\", axis=1)\n",
    "csv = csv.drop(\"2nd_road_number\", axis=1)\n",
    "csv = csv.drop(\"2nd_road_number\", axis=1)\n",
    "csv = csv.drop(\"2nd_road_number\", axis=1)\n",
    "\n",
    "# droping accident_id\n",
    "csv = csv.drop(\"accident_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv[\"year 2017\"] = pd.DatetimeIndex(csv['date']).year-2016\n",
    "csv[\"month\"] = pd.DatetimeIndex(csv['date']).month\n",
    "csv = factorize(csv, \"month\")\n",
    "csv[\"week_day\"] = pd.DatetimeIndex(csv['date']).day_name()\n",
    "csv = factorize(csv, \"week_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    02:30\n",
      "1    00:37\n",
      "2    01:25\n",
      "3    09:15\n",
      "4    07:53\n",
      "Name: time, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(csv[\"time\"].head())\n",
    "\n",
    "# csv[\"police_force\"].corr(csv[\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 150,   37,   85,  555,  473,  569,  533,  605,  591,  585,\n",
       "            ...\n",
       "             990,  670,  450,  785,  915,  690,  780,  810, 1080,  780],\n",
       "           dtype='int64', name='time', length=267549)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = pd.DatetimeIndex(csv[\"time\"])\n",
    "\n",
    "time.hour * 60 + time.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
